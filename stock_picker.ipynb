{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests as regs\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from stocksymbol import StockSymbol\n",
    "import glob\n",
    "from pathlib import Path\n",
    "import lxml\n",
    "import re \n",
    "import os\n",
    "import shutil\n",
    "import reticker\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import tensorflow_text as text\n",
    "import random\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "from pprint import pprint\n",
    "tf.get_logger().setLevel('ERROR')\n",
    "from GoogleNews import GoogleNews\n",
    "googlenews = GoogleNews()\n",
    "%matplotlib inline\n",
    "from gnewsclient import gnewsclient\n",
    "from yahoo_fin import stock_info as si\n",
    "api_key = '51f442a4fab8401ca0e0bc020ee6ae90'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "domains_string = 'hello'\n",
    "todays_date = datetime.datetime.today()\n",
    "todays_date_formatted = todays_date.strftime ('20%y-%m-%d')\n",
    "todays_date_formatted = str(todays_date_formatted)\n",
    "url1 = ('https://newsapi.org/v2/everything?'\n",
    "       'q=stocks&'\n",
    "       f'from={todays_date_formatted}&'\n",
    "       'sortBy=relevancy&'\n",
    "       'domains=marketwatch.com,investing.com,seekingalpha.com,fool.co.uk,ino.com/blog,moneycontrol.com,news.alphastreet.com,equitymaster.com,indiainfoline.com/markets/news,stocksnewsfeed.com,ragingbull.com,scanz.com/blog,wsj.com,nytimes.com'\n",
    "       'page=1&'\n",
    "       'apiKey=51f442a4fab8401ca0e0bc020ee6ae90')\n",
    "\n",
    "url2 = ('https://newsapi.org/v2/everything?'\n",
    "       'q=stocks&'\n",
    "       'domains=marketwatch.com,investing.com,seekingalpha.com,fool.co.uk,ino.com/blog,moneycontrol.com,news.alphastreet.com,equitymaster.com,indiainfoline.com/markets/news,stocksnewsfeed.com,ragingbull.com,scanz.com/blog,wsj.com,nytimes.com'\n",
    "       f'from={todays_date_formatted}&'\n",
    "       'sortBy=relevancy&'\n",
    "       'page=2&'\n",
    "       'apiKey=51f442a4fab8401ca0e0bc020ee6ae90')\n",
    "\n",
    "url3 = ('https://newsapi.org/v2/everything?'\n",
    "       'q=stocks&'\n",
    "       'domains=marketwatch.com,investing.com,seekingalpha.com,fool.co.uk,ino.com/blog,moneycontrol.com,news.alphastreet.com,equitymaster.com,indiainfoline.com/markets/news,stocksnewsfeed.com,ragingbull.com,scanz.com/blog,wsj.com,nytimes.com'\n",
    "       f'from={todays_date_formatted}&'\n",
    "       'sortBy=relevancy&'\n",
    "       'page=3&'\n",
    "       'apiKey=51f442a4fab8401ca0e0bc020ee6ae90')\n",
    "\n",
    "url4 = ('https://newsapi.org/v2/everything?'\n",
    "       'q=stocks&'\n",
    "       'domains=marketwatch.com,investing.com,seekingalpha.com,fool.co.uk,ino.com/blog,moneycontrol.com,news.alphastreet.com,equitymaster.com,indiainfoline.com/markets/news,stocksnewsfeed.com,ragingbull.com,scanz.com/blog,wsj.com,nytimes.com'\n",
    "       f'from={todays_date_formatted}&'\n",
    "       'sortBy=relevancy&'\n",
    "       'page=4&'\n",
    "       'apiKey=51f442a4fab8401ca0e0bc020ee6ae90')\n",
    "\n",
    "url5 = ('https://newsapi.org/v2/everything?'\n",
    "       'q=stocks&'\n",
    "       'domains=marketwatch.com,investing.com,seekingalpha.com,fool.co.uk,ino.com/blog,moneycontrol.com,news.alphastreet.com,equitymaster.com,indiainfoline.com/markets/news,stocksnewsfeed.com,ragingbull.com,scanz.com/blog,wsj.com,nytimes.com'\n",
    "       f'from={todays_date_formatted}&'\n",
    "       'sortBy=relevancy&'\n",
    "       'page=5&'\n",
    "       'apiKey=51f442a4fab8401ca0e0bc020ee6ae90')\n",
    "\n",
    "response1 = regs.get(url1)\n",
    "response2 = regs.get(url2)\n",
    "response3 = regs.get(url3)\n",
    "response4 = regs.get(url4)\n",
    "response5 = regs.get(url5)\n",
    "\n",
    "dict1 = response1.json()\n",
    "dict2 = response2.json()\n",
    "dict3 = response3.json()\n",
    "dict4 = response4.json()\n",
    "dict5 = response5.json()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500\n"
     ]
    }
   ],
   "source": [
    "url_list = []\n",
    "articles = dict1['articles'] + dict2['articles'] + dict3['articles'] + dict4['articles'] + dict5['articles']\n",
    "\n",
    "for item in articles:\n",
    "    if item not in url_list:\n",
    "        url_list.append(item['url'])\n",
    "print(len(url_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_html(my_url):\n",
    "    article = ''\n",
    "    response = regs.request('GET', url = my_url, verify = True)\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "    for item in soup.find_all('p'):\n",
    "        article = article + item.text\n",
    "    return article\n",
    "\n",
    "text_list = [get_html(item) for item in url_list]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss = StockSymbol('abc2b86f-3c33-44fc-b01b-926a904bd13c')\n",
    "symbol_list_us = ss.get_symbol_list(market=\"US\")\n",
    "def get_sym(big_list):\n",
    "    new_list = []\n",
    "    for item in big_list:\n",
    "        new_list.append(item['symbol'])\n",
    "    return new_list\n",
    "\n",
    "my_sym_list = get_sym(symbol_list_us)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ticker(list):\n",
    "    ticker_list = []\n",
    "    pair = []\n",
    "    for text in list:\n",
    "        count = 0\n",
    "        tick = reticker.TickerExtractor().extract(text)\n",
    "        for item in tick:\n",
    "            if item in my_sym_list:\n",
    "                match = re.search(item, text)\n",
    "                pair = []\n",
    "                start = match.start() - 500\n",
    "                end = match.end() + 500\n",
    "                if start < 0:\n",
    "                    start = 0\n",
    "                    \n",
    "                if end > len(text) - 1:\n",
    "                    end = -1\n",
    "                chunk = text[start:end]\n",
    "                pair.append(text[match.start():match.end()])\n",
    "                pair.append(chunk)\n",
    "                ticker_list.append(pair)\n",
    "    return ticker_list\n",
    "poss_ticker = get_ticker(text_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_new_list(list):\n",
    "    text_list = []\n",
    "    match_list = []\n",
    "    for item in list:\n",
    "        text_list.append(item[1])\n",
    "        match_list.append(item[0])\n",
    "    return text_list, match_list\n",
    "\n",
    "string_list, match_list = create_new_list(poss_ticker)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metal device set to: Apple M1 Max\n",
      "\n",
      "systemMemory: 64.00 GB\n",
      "maxCacheSize: 24.00 GB\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-19 21:17:48.591409: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2022-07-19 21:17:48.591573: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n",
      "2022-07-19 21:18:11.061055: W tensorflow/core/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n",
      "2022-07-19 21:18:11.814391: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "saved_model_path = '/Users/michaelscoleri/Desktop/Coding/Personal/Python/Stock_scraper/Scaper3.0_bert'\n",
    "reloaded_model = tf.saved_model.load(saved_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-19 21:19:23.512261: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    }
   ],
   "source": [
    "with tf.device('/cpu:0'):\n",
    "    reloaded_results1 = tf.sigmoid(reloaded_model(tf.constant(string_list)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_good_match(match_list_new, seq_list_new, string_list):\n",
    "    hit = []\n",
    "    for item, seq, string in zip(match_list_new, seq_list_new, string_list):\n",
    "        if item > .7:\n",
    "            pair = []\n",
    "            pair.append(seq)\n",
    "            pair.append(f'{item[0]:.6f}')\n",
    "            pair.append(string)\n",
    "            hit.append(pair)\n",
    "    return hit\n",
    "\n",
    "finished_hits = return_good_match(reloaded_results1, match_list, string_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_var = datetime.datetime.today()\n",
    "temp_df = pd.DataFrame(finished_hits)\n",
    "temp_df['Occur'] = temp_df.groupby(0)[0].transform('size')\n",
    "temp_df['Date Added'] =  temp_var.strftime ('%b-%d')\n",
    "temp_df = temp_df.rename(columns = {1:'Score'})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_to_num(row):\n",
    "    number = row['Score']\n",
    "    number = float(number)\n",
    "    return number\n",
    "\n",
    "temp_df['Score'] = temp_df.apply(transform_to_num, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "mean_df = (temp_df.groupby(0))['Score'].mean()\n",
    "mean_df = mean_df.to_frame('Mean')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_df = temp_df.rename(columns={1:'Score'})\n",
    "temp_df = temp_df.sort_values('Score', ascending=False)\n",
    "temp_df = pd.merge(temp_df, mean_df, left_on=0, right_on = 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_df = temp_df.drop_duplicates(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_df = pd.read_excel('/Users/michaelscoleri/Desktop/Coding/Personal/Python/Stock_scraper/finished_hits.xlsx')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      None\n",
       "1      None\n",
       "2      None\n",
       "3      None\n",
       "4      None\n",
       "       ... \n",
       "500    None\n",
       "501    None\n",
       "502    None\n",
       "503    None\n",
       "504    None\n",
       "Length: 505, dtype: object"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def remove_old_date(row):\n",
    "    ten_days = datetime.datetime.today() - datetime.timedelta(days=10)\n",
    "    ten_days_formatted = ten_days.strftime ('%b-%d')\n",
    "    if row['Date Added'] == ten_days_formatted:\n",
    "        current_df.drop(row, axis = 0)\n",
    "    return\n",
    "\n",
    "current_df.apply(remove_old_date, axis = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_df = pd.concat([current_df, temp_df], axis = 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum_df = current_df['Occur'].groupby(by=current_df[0]).sum()\n",
    "current_df = current_df.drop('Occur', axis = 1)\n",
    "current_df = pd.merge(current_df, sum_df, left_on=0, right_on=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_df = current_df['Mean'].groupby(by=current_df[0]).mean()\n",
    "mean_df = mean_df.to_frame('Mean')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_df = current_df.sort_values('Score', ascending=False)\n",
    "current_df = pd.merge(current_df, mean_df, left_on=0, right_on=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_df = current_df.drop('Mean_x', axis = 1)\n",
    "current_df = current_df.rename(columns={'Mean_y': 'Mean'})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_df = current_df.drop_duplicates(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_current_price(row):\n",
    "    name = row[0]\n",
    "    try:\n",
    "        price = si.get_live_price(name)\n",
    "    except:\n",
    "        price = np.NaN\n",
    "    return price\n",
    "current_df[\"Price\"] = current_df.apply(add_current_price, axis = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_df.to_excel('/Users/michaelscoleri/Desktop/Coding/Personal/Python/Stock_scraper/finished_hits.xlsx', index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 ('tf')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "52ee2977380704a66854748a73250e0671a9318bd5b3fd45a3df9f851ae61629"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
